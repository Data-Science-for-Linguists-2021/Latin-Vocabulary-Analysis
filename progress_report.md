# Progress report:
## Frances Harrington, frh19@pitt.edu
## 1st Progress Report:
### 3/5/2021

   ## Summary of what I have accomplished as well as what I will do next:
   I have scraped the texts from the Latin Library website using a [spider](http://localhost:8888/notebooks/Documents/ling1340/Latin-Vocabulary-Analysis/LatLibSpider.ipynb) I built. With this data I have been able to deduce the number of texts as well as print out the textual content and titles. Once I constructed my spider, I appended the data to empty lists which I then converted to Series in order to put them into a DataFrame. This DataFrame right now consists of the titles and their corresponding texts. After building this DataFrame I pickled it and saved it to my data folder, which is included in the .gitignore. I also have a sample of ten files pickled in the [data_samples](http://localhost:8888/tree/Documents/ling1340/Latin-Vocabulary-Analysis/data_samples) folder.
    I was able to extract the urls of each author and work by using multiple parse functions and xpath notation as well as list comprehension. The list comprehension was used in the second parser to add the new path onto the base url. Through this process I learned a lot about spiders and the way that they are constructed as well as how to use them. 
    Currently I have not done any analysis on this data. I have fetched the information from the Latin Library website, put that information into the DataFrame, and pickled that Dataframe. Next I will focus on building more information into the preexisting DataFrame (i.e. URLs, genres, style) as well as diving into the analysis portion. Because I have collected data from many different eras it might also be relevent to include era (pinpointing exact years are difficult with the more ancient texts) in the analysis/DataFrame.
    
   ## Data sharing plan:
   While I could share the full data/texts, I think that the best option for my "sharing plan" for this project is to provide the links for anyone who wishes to access the site, but not provide all of the data. The data that I will provide will be a select few of the texts that were posted by the site founder/manager himself. I would do this because while the texts are reported to be in the public domain by the site's creator/manager, he does leave the disclaimer that if there are any copyright claims he should be contacted. So, while he does seem to have done a thorough job in crediting his sources, I would ideally like to keep distribution of the texts to a minimum just in case. So, although anyone with a link can access the texts for themselves, I personally will not be responsible for distributing them.   
